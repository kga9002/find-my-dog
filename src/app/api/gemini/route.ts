import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';
import dogBreeds from '../../data/breed.json';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

// ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í•¨ìˆ˜ (ì•ˆì „í•˜ê²Œ ë²¡í„° ê¸¸ì´ ë§ì¶¤)
function cosineSimilarity(a: number[], b: number[]): number {
	const len = Math.min(a.length, b.length);
	const dot = a.slice(0, len).reduce((sum, v, i) => sum + v * b[i], 0);
	const magA = Math.sqrt(a.slice(0, len).reduce((sum, v) => sum + v * v, 0));
	const magB = Math.sqrt(b.slice(0, len).reduce((sum, v) => sum + v * v, 0));
	return dot / (magA * magB);
}

export async function POST(req: NextRequest) {
	try {
		const { message, conversationHistory = [] } = await req.json();

		// ëŒ€í™” íˆìŠ¤í† ë¦¬ ëˆ„ì 
		const newHistory = [
			...conversationHistory,
			{ role: 'user', content: message },
		];
		const fullConversation = newHistory
			.map((msg) => `${msg.role}: ${msg.content}`)
			.join('\n');

		// ì‚¬ìš©ì ë©”ì‹œì§€ ê°œìˆ˜
		const userMessageCount = newHistory.filter(
			(msg) => msg.role === 'user'
		).length;

		const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
		let judgment = 'CONTINUE';

		// 4ë²ˆì§¸ ë©”ì‹œì§€ë¶€í„°ëŠ” ë¬´ì¡°ê±´ ì¶”ì²œ
		if (userMessageCount >= 5) {
			judgment = 'RECOMMEND';
		} else {
			const judgePrompt = `
ëŒ€í™”: ${fullConversation}

ê°•ì•„ì§€ ì¶”ì²œí•  ë§Œí¼ ì •ë³´ê°€ ì¶©ë¶„í•œê°€ìš”?
ì‚¬ìš©ìê°€ 3ë²ˆ ì´ìƒ ë‹µë³€í–ˆê³  ì„±ê²©ì´ ì–´ëŠì •ë„ íŒŒì•…ë˜ë©´ "RECOMMEND"
ì•„ì§ ë” ì•Œì•„ì•¼ í•˜ë©´ "CONTINUE"

ë‹µë³€: CONTINUE ë˜ëŠ” RECOMMEND ì¤‘ í•˜ë‚˜ë§Œ`;
			const judgeResult = await model.generateContent(judgePrompt);
			judgment = (await judgeResult.response.text()).trim();
		}

		if (judgment === 'RECOMMEND') {
			// 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì„ë² ë”©
			const embedModel = genAI.getGenerativeModel({ model: 'embedding-001' });
			const embedRes = await embedModel.embedContent(message);
			const userVector = embedRes.embedding.values;

			// 2. í’ˆì¢…ê³¼ ìœ ì‚¬ë„ ê³„ì‚° (ì„ë² ë”©ì€ breed.jsonì— ìˆìŒ)
			const scored = dogBreeds.map((breed: any) => {
				const sim = cosineSimilarity(userVector, breed.vector);
				return { ...breed, score: sim };
			});

			// 3. ìƒìœ„ 3ê°œ ì¶”ì¶œ
			const topBreeds = scored.sort((a, b) => b.score - a.score).slice(0, 3);

			// 4. Geminiì—ê²Œ ìµœì¢… ì¶”ì²œ ìš”ì²­
			const prompt = `
ì‚¬ìš©ì ì„¤ëª…: ${message}
í›„ë³´ í’ˆì¢…:
${topBreeds.map((b) => `- ${b.name}: ${b.description}`).join('\n')}

ìœ„ í›„ë³´ ì¤‘ì—ì„œ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì˜ ë§ëŠ” í’ˆì¢…ì„ í•œ ê°€ì§€ ê³ ë¥´ê³ ,
ê°„ë‹¨í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.`;

			const result = await model.generateContent(prompt);
			const explanation = await result.response.text();

			const buttonMessage = `ğŸ‰ ë‹¹ì‹ ì—ê²Œ ë”± ë§ëŠ” ê°•ì•„ì§€ í’ˆì¢…ì„ ì°¾ì•˜ì–´ìš”! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.`;

			return NextResponse.json({
				message: buttonMessage,
				type: 'recommendation',
				recommendedBreed: topBreeds[0].name,
				explanation,
				conversationHistory: [
					...newHistory,
					{ role: 'assistant', content: buttonMessage },
				],
			});
		} else {
			// ê³„ì† ëŒ€í™”
			const chatPrompt = `
ëŒ€í™”: ${fullConversation}

ê°•ì•„ì§€ ì¶”ì²œ ìƒë‹´ì‚¬ë¡œì„œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
- 1-2ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ë‹µë³€
- ì‚¬ìš©ì ë‹µë³€ì— ê³µê° í•œë§ˆë”” + ë˜ ë‹¤ë¥¸ ì§ˆë¬¸ í•˜ë‚˜
- ìƒí™œíŒ¨í„´, ì„±ê²©, ê±°ì£¼í™˜ê²½ ë“±ì„ íŒŒì•…í•˜ëŠ”ê²ƒì´ ëª©í‘œ
- ì¹œê·¼í•˜ê³  ê°„ë‹¨í•˜ê²Œ`;

			const chatResult = await model.generateContent(chatPrompt);
			const response = await chatResult.response.text();

			return NextResponse.json({
				message: response,
				type: 'conversation',
				conversationHistory: [
					...newHistory,
					{ role: 'assistant', content: response },
				],
			});
		}
	} catch (error) {
		console.error('Chat API ì˜¤ë¥˜:', error);
		return NextResponse.json(
			{ error: 'ëŒ€í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
			{ status: 500 }
		);
	}
}
